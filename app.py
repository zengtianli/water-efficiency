"""æµ™æ°´è®¾è®¡-æ°´æ•ˆè¯„ä¼°åˆ†æç³»ç»Ÿ"""
import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from io import BytesIO

from core.sample_data import (
    macro_cycle_raw, meso_cycle_raw,
    MICRO_FUNCS, default_ahp_matrix, create_sample_xlsx,
)
from core.indicators import (
    calc_macro_indicators, calc_meso_indicators, calc_micro_indicators,
    aggregate_micro_by_year,
)
from core.ahp import ahp_weights, combined_weights
from core.critic import critic_weights
from core.topsis import topsis_evaluate, classify, build_result_table

# C1-C10 æŒ‡æ ‡æ–¹å‘: 1=æ­£å‘, -1=è´Ÿå‘
DIRECTIONS_ALL = np.array([1, 1, -1, 1, 1, 1, 1, 1, 1, 1])
ALL_INDICATOR_COLS = [
    "C1-å†ç”Ÿæ°´åˆ©ç”¨ç‡(%)", "C2-ä¸‡å…ƒå·¥ä¸šå¢åŠ å€¼å†ç”Ÿæ°´åˆ©ç”¨é‡(mÂ³/ä¸‡å…ƒ)",
    "C3-å†ç”Ÿæ°´ç®¡ç½‘æ¼æŸç‡(%)", "C4-å†ç”Ÿæ°´åˆ©ç”¨é‡å¢é•¿ç‡(%)",
    "C5-ä¼ä¸šå†ç”Ÿæ°´ç®¡ç½‘è¦†ç›–ç‡(%)", "C6-å†ç”Ÿæ°´åˆ©ç”¨é‡å¢é•¿ç‡(%)",
    "C7-å·¥ä¸šç”¨æ°´é‡å¤åˆ©ç”¨ç‡(%)", "C8-é—´æ¥å†·å´æ°´å¾ªç¯åˆ©ç”¨ç‡(%)",
    "C9-å·¥è‰ºæ°´å›ç”¨ç‡(%)", "C10-å†ç”Ÿæ°´åˆ©ç”¨é‡å¢é•¿ç‡(%)",
]

st.set_page_config(page_title="æ°´æ•ˆè¯„ä¼°åˆ†æç³»ç»Ÿ", layout="wide")
st.title("æµ™æ°´è®¾è®¡-æ°´æ•ˆè¯„ä¼°åˆ†æç³»ç»Ÿ")
st.caption("å·¥ä¸šé›†èšåŒºæ°´æ•ˆè¯„ä¼° | AHP + CRITIC + TOPSIS")

# â”€â”€ ä¾§è¾¹æ  â”€â”€
st.sidebar.header("æ•°æ®è®¾ç½®")
data_source = st.sidebar.radio("æ•°æ®æ¥æº", ["ç¤ºä¾‹æ•°æ®", "ä¸Šä¼ æ•°æ®"])
alpha = st.sidebar.slider("AHPæƒé‡å æ¯” (Î±)", 0.0, 1.0, 0.5, 0.05)

# ä¸‹è½½ç¤ºä¾‹æ•°æ®
st.sidebar.markdown("---")
st.sidebar.download_button(
    "ä¸‹è½½ç¤ºä¾‹æ•°æ® (Excel)",
    data=create_sample_xlsx(),
    file_name="ç¤ºä¾‹æ•°æ®.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
)

# â”€â”€ åŠ è½½æ•°æ® â”€â”€
df_macro = None
df_meso = None
micro_dict = {}  # {å¹´åº¦: DataFrame}
ahp_matrix_df = default_ahp_matrix()

if data_source == "ç¤ºä¾‹æ•°æ®":
    df_macro = macro_cycle_raw()
    df_meso = meso_cycle_raw()
    micro_dict = {year: func() for year, func in MICRO_FUNCS.items()}
else:
    st.sidebar.markdown("---")
    st.sidebar.subheader("ä¸Šä¼ æ•°æ®æ–‡ä»¶")
    uploaded = st.sidebar.file_uploader(
        "ä¸Šä¼ æ•°æ® Excelï¼ˆå«å¤§å¾ªç¯/å°å¾ªç¯/ç‚¹å¾ªç¯/AHP sheetï¼‰",
        type=["xlsx"],
    )
    if uploaded:
        xls = pd.ExcelFile(uploaded)
        sheet_names = xls.sheet_names
        # å¤§å¾ªç¯
        if "å¤§å¾ªç¯" in sheet_names:
            df_macro = pd.read_excel(xls, sheet_name="å¤§å¾ªç¯")
        # å°å¾ªç¯
        if "å°å¾ªç¯" in sheet_names:
            df_meso = pd.read_excel(xls, sheet_name="å°å¾ªç¯")
        # ç‚¹å¾ªç¯ï¼šåŒ¹é… "ç‚¹å¾ªç¯-xxxxå¹´" æ ¼å¼çš„ sheet
        for sn in sheet_names:
            if sn.startswith("ç‚¹å¾ªç¯-"):
                year_label = sn.replace("ç‚¹å¾ªç¯-", "")
                micro_dict[year_label] = pd.read_excel(xls, sheet_name=sn)
        # AHP
        if "AHPåˆ¤æ–­çŸ©é˜µ" in sheet_names:
            ahp_matrix_df = pd.read_excel(xls, sheet_name="AHPåˆ¤æ–­çŸ©é˜µ", index_col=0)

# â”€â”€ ä¸»ç•Œé¢ Tabs â”€â”€
tab1, tab2, tab3, tab4 = st.tabs(
    ["ğŸ“Š æ•°æ®ä¸æŒ‡æ ‡", "âš–ï¸ æƒé‡è®¡ç®—", "ğŸ† TOPSISè¯„ä»·", "ğŸ“ˆ å¯è§†åŒ–åˆ†æ"]
)

# ================================================================
# Tab 1: æ•°æ®ä¸æŒ‡æ ‡è®¡ç®—
# ================================================================
with tab1:
    st.header("åŸå§‹æ•°æ®ä¸æŒ‡æ ‡è®¡ç®—")

    st.subheader("å¤§å¾ªç¯å±‚é¢")
    if df_macro is not None:
        st.dataframe(df_macro, use_container_width=True)
        ind_macro = calc_macro_indicators(df_macro)
        st.markdown("**è®¡ç®—ç»“æœ (C1-C4)**")
        st.dataframe(ind_macro, use_container_width=True)
    else:
        st.info("è¯·ä¸Šä¼ åŒ…å«ã€Œå¤§å¾ªç¯ã€sheet çš„æ•°æ®æ–‡ä»¶")

    st.markdown("---")
    st.subheader("å°å¾ªç¯å±‚é¢")
    if df_meso is not None:
        st.dataframe(df_meso, use_container_width=True)
        ind_meso = calc_meso_indicators(df_meso)
        st.markdown("**è®¡ç®—ç»“æœ (C5-C6)**")
        st.dataframe(ind_meso, use_container_width=True)
    else:
        st.info("è¯·ä¸Šä¼ åŒ…å«ã€Œå°å¾ªç¯ã€sheet çš„æ•°æ®æ–‡ä»¶")

    st.markdown("---")
    st.subheader("ç‚¹å¾ªç¯å±‚é¢ï¼ˆä¼ä¸šæ•°æ®ï¼‰")

    if micro_dict:
        year_options = list(micro_dict.keys())
        year_choice = st.radio("é€‰æ‹©å¹´åº¦", year_options, horizontal=True)
        df_micro = micro_dict[year_choice]
        st.dataframe(df_micro, use_container_width=True)
        ind_micro = calc_micro_indicators(df_micro)
        st.markdown("**è®¡ç®—ç»“æœ (C7-C10)**")
        st.dataframe(ind_micro, use_container_width=True)
        st.session_state["ind_micro"] = ind_micro
        st.session_state["df_micro"] = df_micro
    else:
        st.info("è¯·ä¸Šä¼ åŒ…å«ã€Œç‚¹å¾ªç¯-xxxxå¹´ã€sheet çš„æ•°æ®æ–‡ä»¶")

# ================================================================
# Tab 2: æƒé‡è®¡ç®— (C1-C10 å…¨è¦†ç›–)
# ================================================================
with tab2:
    st.header("æƒé‡è®¡ç®—ï¼ˆC1-C10ï¼‰")

    # æ„å»ºå¹´åº¦ Ã— C1-C10 çŸ©é˜µ
    can_build = (df_macro is not None and df_meso is not None and micro_dict)
    if not can_build:
        st.warning("è¯·å…ˆåœ¨ã€Œæ•°æ®ä¸æŒ‡æ ‡ã€é¡µåŠ è½½å®Œæ•´çš„å¤§å¾ªç¯ã€å°å¾ªç¯ã€ç‚¹å¾ªç¯æ•°æ®")
        st.stop()

    ind_macro = calc_macro_indicators(df_macro)
    ind_meso = calc_meso_indicators(df_meso)
    ind_micro_agg = aggregate_micro_by_year(micro_dict)

    # æŒ‰å¹´åº¦åˆå¹¶: å¤§å¾ªç¯(C1-C4) + å°å¾ªç¯(C5-C6) + ç‚¹å¾ªç¯å‡å€¼(C7-C10)
    merged = ind_macro.merge(ind_meso, on="å¹´åº¦", how="inner")
    merged = merged.merge(ind_micro_agg, on="å¹´åº¦", how="inner")

    # åªä¿ç•™æœ‰å®Œæ•´æ•°æ®çš„è¡Œï¼ˆå»æ‰å« NaN çš„å¹´åº¦ï¼Œå¦‚å¢é•¿ç‡é¦–å¹´ï¼‰
    indicator_cols = [c for c in merged.columns if c.startswith("C")]
    merged_clean = merged.dropna(subset=indicator_cols).reset_index(drop=True)

    if len(merged_clean) < 2:
        st.warning("æœ‰æ•ˆå¹´åº¦æ•°æ®ä¸è¶³ï¼ˆè‡³å°‘éœ€è¦2å¹´å®Œæ•´æ•°æ®ï¼‰ï¼Œè¯·æ£€æŸ¥æ•°æ®")
        st.stop()

    st.markdown("**å¹´åº¦ç»¼åˆæŒ‡æ ‡çŸ©é˜µ**ï¼ˆç‚¹å¾ªç¯ä¸ºä¼ä¸šå‡å€¼ï¼‰")
    st.dataframe(merged_clean, use_container_width=True)

    n_ind = len(indicator_cols)
    # æŒ‡æ ‡æ–¹å‘ï¼šC3 ä¸ºè´Ÿå‘ï¼Œå…¶ä½™æ­£å‘
    directions = np.array([
        -1 if "æ¼æŸ" in c else 1 for c in indicator_cols
    ])

    col_ahp, col_critic = st.columns(2)

    with col_ahp:
        st.subheader("AHP ä¸»è§‚èµ‹æƒ")
        st.markdown("åˆ¤æ–­çŸ©é˜µï¼ˆå¯ç¼–è¾‘ï¼‰ï¼š")
        edited_ahp = st.data_editor(
            ahp_matrix_df, use_container_width=True, num_rows="fixed"
        )
        matrix = edited_ahp.values.astype(float)
        w_ahp, cr, consistent = ahp_weights(matrix)

        st.markdown(f"**ä¸€è‡´æ€§æ¯”ç‡ CR = {cr:.4f}**")
        if consistent:
            st.success("é€šè¿‡ä¸€è‡´æ€§æ£€éªŒ (CR < 0.1)")
        else:
            st.error("æœªé€šè¿‡ä¸€è‡´æ€§æ£€éªŒï¼Œè¯·è°ƒæ•´åˆ¤æ–­çŸ©é˜µ")

        ahp_df = pd.DataFrame({
            "æŒ‡æ ‡": indicator_cols,
            "AHPæƒé‡": np.round(w_ahp, 4),
        })
        st.dataframe(ahp_df, use_container_width=True, hide_index=True)

    with col_critic:
        st.subheader("CRITIC å®¢è§‚èµ‹æƒ")
        data_matrix = merged_clean[indicator_cols].values.astype(float)
        w_critic = critic_weights(data_matrix, directions)

        critic_df = pd.DataFrame({
            "æŒ‡æ ‡": indicator_cols,
            "CRITICæƒé‡": np.round(w_critic, 4),
        })
        st.dataframe(critic_df, use_container_width=True, hide_index=True)

    # â”€â”€ ç»„åˆæƒé‡ â”€â”€
    st.markdown("---")
    st.subheader("ç»„åˆæƒé‡")
    w_combined = combined_weights(w_ahp, w_critic, alpha)

    weight_df = pd.DataFrame({
        "æŒ‡æ ‡": indicator_cols,
        "AHPæƒé‡": np.round(w_ahp, 4),
        "CRITICæƒé‡": np.round(w_critic, 4),
        "ç»„åˆæƒé‡": np.round(w_combined, 4),
    })
    st.dataframe(weight_df, use_container_width=True, hide_index=True)

    fig_w = go.Figure()
    fig_w.add_trace(go.Bar(name="AHP", x=indicator_cols, y=w_ahp))
    fig_w.add_trace(go.Bar(name="CRITIC", x=indicator_cols, y=w_critic))
    fig_w.add_trace(go.Bar(name="ç»„åˆ", x=indicator_cols, y=w_combined))
    fig_w.update_layout(barmode="group", height=350, title="æƒé‡å¯¹æ¯”")
    st.plotly_chart(fig_w, use_container_width=True)

    # â”€â”€ åˆ†å±‚è¯„åˆ† â”€â”€
    st.markdown("---")
    st.subheader("åˆ†å±‚è¯„åˆ†ä¸è¯•ç‚¹æ±‡æ€»")

    # å±‚é¢åˆ†ç»„å®šä¹‰
    LAYER_GROUPS = {
        "å¤§å¾ªç¯": ["C1", "C2", "C3", "C4"],
        "å°å¾ªç¯": ["C5", "C6"],
        "ç‚¹å¾ªç¯": ["C7", "C8", "C9", "C10"],
    }

    def _layer_score(layer_prefixes):
        """è®¡ç®—æŸå±‚é¢çš„å¹´åº¦ç™¾åˆ†åˆ¶è¯„åˆ†"""
        idx = [i for i, c in enumerate(indicator_cols)
               if c.split("-")[0] in layer_prefixes]
        sub_vals = merged_clean[indicator_cols].values[:, idx].astype(float)
        sub_dirs = directions[idx]
        sub_w = w_combined[idx]
        sub_w = sub_w / sub_w.sum()  # å½’ä¸€åŒ–å­æƒé‡
        normed = np.zeros_like(sub_vals)
        for j in range(len(idx)):
            col_vals = sub_vals[:, j]
            rng = col_vals.max() - col_vals.min()
            if rng == 0:
                normed[:, j] = 1.0
            elif sub_dirs[j] == 1:
                normed[:, j] = (col_vals - col_vals.min()) / rng
            else:
                normed[:, j] = (col_vals.max() - col_vals) / rng
        return np.round((normed @ sub_w) * 100, 2)

    # è®¡ç®—å„å±‚é¢è¯„åˆ†
    layer_scores = {}
    layer_weights = {}
    for name, prefixes in LAYER_GROUPS.items():
        layer_scores[name] = _layer_score(prefixes)
        idx = [i for i, c in enumerate(indicator_cols)
               if c.split("-")[0] in prefixes]
        layer_weights[name] = w_combined[idx].sum()

    # ä¸‰åˆ—å±•ç¤ºå„å±‚é¢è¯„åˆ†
    col_l1, col_l2, col_l3 = st.columns(3)
    for col, (name, prefixes) in zip(
        [col_l1, col_l2, col_l3], LAYER_GROUPS.items()
    ):
        with col:
            w_pct = f"{layer_weights[name] * 100:.1f}%"
            st.markdown(f"**{name}è¯„åˆ†**ï¼ˆå±‚é¢æƒé‡ {w_pct}ï¼‰")
            layer_df = pd.DataFrame({
                "å¹´åº¦": merged_clean["å¹´åº¦"].values,
                "è¯„åˆ†": layer_scores[name],
            })
            st.dataframe(layer_df, use_container_width=True, hide_index=True)

    # è¯•ç‚¹æ±‡æ€»è¯„åˆ†
    st.markdown("---")
    st.markdown("**è¯•ç‚¹æ±‡æ€»è¯„åˆ†** = å¤§å¾ªç¯è¯„åˆ† Ã— wâ‚ + å°å¾ªç¯è¯„åˆ† Ã— wâ‚‚ + ç‚¹å¾ªç¯è¯„åˆ† Ã— wâ‚ƒ")
    pilot_total = np.zeros(len(merged_clean))
    for name in LAYER_GROUPS:
        pilot_total += layer_scores[name] * layer_weights[name]
    pilot_total = np.round(pilot_total, 2)

    pilot_df = pd.DataFrame({
        "å¹´åº¦": merged_clean["å¹´åº¦"].values,
        "å¤§å¾ªç¯è¯„åˆ†": layer_scores["å¤§å¾ªç¯"],
        "å°å¾ªç¯è¯„åˆ†": layer_scores["å°å¾ªç¯"],
        "ç‚¹å¾ªç¯è¯„åˆ†": layer_scores["ç‚¹å¾ªç¯"],
        "æ±‡æ€»è¯„åˆ†": pilot_total,
    })
    st.dataframe(pilot_df, use_container_width=True, hide_index=True)

    # å±‚é¢æƒé‡è¡¨
    lw_df = pd.DataFrame({
        "å±‚é¢": list(layer_weights.keys()),
        "æƒé‡": [round(v, 4) for v in layer_weights.values()],
    })
    st.dataframe(lw_df, use_container_width=True, hide_index=True)

    # å­˜å…¥ session_state
    st.session_state["w_combined"] = w_combined
    st.session_state["directions"] = directions
    st.session_state["indicator_cols"] = indicator_cols
    st.session_state["weight_df"] = weight_df
    st.session_state["pilot_df"] = pilot_df
    st.session_state["layer_scores"] = layer_scores
    st.session_state["layer_weights"] = layer_weights
    st.session_state["merged_clean"] = merged_clean

# ================================================================
# Tab 3: TOPSIS ä¼ä¸šè¯„ä»· (C7-C10)
# ================================================================
with tab3:
    st.header("TOPSIS ä¼ä¸šè¯„ä»·")

    needed = ["ind_micro", "w_combined", "indicator_cols"]
    if not all(k in st.session_state for k in needed):
        st.warning("è¯·å…ˆå®Œæˆã€Œæ•°æ®ä¸æŒ‡æ ‡ã€å’Œã€Œæƒé‡è®¡ç®—ã€")
        st.stop()

    ind_micro = st.session_state["ind_micro"]
    w_all = st.session_state["w_combined"]
    all_cols = st.session_state["indicator_cols"]

    # æå– C7-C10 å­é›†æƒé‡å¹¶é‡æ–°å½’ä¸€åŒ–
    micro_cols = [c for c in ind_micro.columns if c.startswith("C")]
    micro_idx = [i for i, c in enumerate(all_cols) if c in micro_cols]
    w_micro = w_all[micro_idx]
    w_micro = w_micro / w_micro.sum()  # å½’ä¸€åŒ–
    dirs_micro = np.ones(len(micro_cols))  # C7-C10 å…¨éƒ¨æ­£å‘

    st.markdown(f"**ä½¿ç”¨ C7-C10 ç»„åˆæƒé‡ï¼ˆä»å…¨å±€æƒé‡æå–å¹¶å½’ä¸€åŒ–ï¼‰**")
    micro_weight_df = pd.DataFrame({
        "æŒ‡æ ‡": micro_cols,
        "å½’ä¸€åŒ–æƒé‡": np.round(w_micro, 4),
    })
    st.dataframe(micro_weight_df, use_container_width=True, hide_index=True)

    data_mat = ind_micro[micro_cols].values.astype(float)
    names = ind_micro["ä¼ä¸šåç§°"].tolist()

    scores, closeness = topsis_evaluate(data_mat, w_micro, dirs_micro)
    result_df = build_result_table(names, scores, closeness)

    def _color_grade(row):
        color = row["é¢„è­¦é¢œè‰²"]
        return [f"background-color: {color}20" for _ in row]

    st.dataframe(
        result_df.style.apply(_color_grade, axis=1),
        use_container_width=True,
        hide_index=True,
    )

    st.markdown("### ç­‰çº§åˆ†å¸ƒ")
    grade_counts = result_df["æ°´æ•ˆç­‰çº§"].value_counts()
    fig_pie = px.pie(
        values=grade_counts.values,
        names=grade_counts.index,
        color=grade_counts.index,
        color_discrete_map={
            "æ°´æ•ˆé¢†è·‘": "#1890ff",
            "æ°´æ•ˆå…ˆè¿›": "#52c41a",
            "æ°´æ•ˆè¾¾æ ‡": "#faad14",
            "æ°´æ•ˆå¾…æ”¹è¿›": "#f5222d",
        },
    )
    fig_pie.update_layout(height=350)
    st.plotly_chart(fig_pie, use_container_width=True)

    # â”€â”€ å¯¼å‡ºç»“æœ â”€â”€
    st.markdown("### å¯¼å‡ºç»“æœ")
    buf = BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        has_layers = "layer_scores" in st.session_state
        if has_layers:
            mc = st.session_state["merged_clean"]
            ls = st.session_state["layer_scores"]
            lw = st.session_state["layer_weights"]

        # â”€â”€ Sheet 1: ç»¼åˆè¯„ä»·ç»“æœ â”€â”€
        row = 0
        ws_name = "ç»¼åˆè¯„ä»·ç»“æœ"
        # è¯•ç‚¹æ±‡æ€»è¯„åˆ†
        if "pilot_df" in st.session_state:
            pilot = st.session_state["pilot_df"]
            pd.DataFrame([["ã€è¯•ç‚¹æ±‡æ€»è¯„åˆ†ã€‘"]]).to_excel(
                writer, sheet_name=ws_name, startrow=row,
                index=False, header=False,
            )
            row += 1
            pilot.to_excel(
                writer, sheet_name=ws_name, startrow=row, index=False,
            )
            row += len(pilot) + 2
        # TOPSIS ä¼ä¸šè¯„ä»·
        pd.DataFrame([["ã€TOPSISä¼ä¸šè¯„ä»·ã€‘"]]).to_excel(
            writer, sheet_name=ws_name, startrow=row,
            index=False, header=False,
        )
        row += 1
        result_df.to_excel(
            writer, sheet_name=ws_name, startrow=row, index=False,
        )

        # â”€â”€ Sheet 2: æŒ‡æ ‡æ˜ç»† â”€â”€
        row = 0
        ws_name = "æŒ‡æ ‡æ˜ç»†"
        # å¤§å¾ªç¯ï¼šåŸå§‹æ•°æ®ä¸æŒ‡æ ‡æ¨ªå‘åˆå¹¶
        if df_macro is not None:
            ind_mac = calc_macro_indicators(df_macro)
            macro_merged = df_macro.merge(
                ind_mac, on="å¹´åº¦", how="left",
            )
            pd.DataFrame([["ã€å¤§å¾ªç¯ â€” åŸå§‹æ•°æ® + æŒ‡æ ‡(C1-C4)ã€‘"]]).to_excel(
                writer, sheet_name=ws_name, startrow=row,
                index=False, header=False,
            )
            row += 1
            macro_merged.to_excel(
                writer, sheet_name=ws_name, startrow=row, index=False,
            )
            row += len(macro_merged) + 1
            # å¤§å¾ªç¯è¯„åˆ†
            if has_layers:
                pd.DataFrame({
                    "å¹´åº¦": mc["å¹´åº¦"].values,
                    "å¤§å¾ªç¯è¯„åˆ†": ls["å¤§å¾ªç¯"],
                    "å±‚é¢æƒé‡": round(lw["å¤§å¾ªç¯"], 4),
                }).to_excel(
                    writer, sheet_name=ws_name, startrow=row, index=False,
                )
                row += len(mc) + 2

        # å°å¾ªç¯
        if df_meso is not None:
            ind_mes = calc_meso_indicators(df_meso)
            meso_merged = df_meso.merge(
                ind_mes, on="å¹´åº¦", how="left",
            )
            pd.DataFrame([["ã€å°å¾ªç¯ â€” åŸå§‹æ•°æ® + æŒ‡æ ‡(C5-C6)ã€‘"]]).to_excel(
                writer, sheet_name=ws_name, startrow=row,
                index=False, header=False,
            )
            row += 1
            meso_merged.to_excel(
                writer, sheet_name=ws_name, startrow=row, index=False,
            )
            row += len(meso_merged) + 1
            if has_layers:
                pd.DataFrame({
                    "å¹´åº¦": mc["å¹´åº¦"].values,
                    "å°å¾ªç¯è¯„åˆ†": ls["å°å¾ªç¯"],
                    "å±‚é¢æƒé‡": round(lw["å°å¾ªç¯"], 4),
                }).to_excel(
                    writer, sheet_name=ws_name, startrow=row, index=False,
                )
                row += len(mc) + 2

        # ç‚¹å¾ªç¯ï¼šå„å¹´åº¦ä¼ä¸šæŒ‡æ ‡
        for year, df_raw in micro_dict.items():
            ind_y = calc_micro_indicators(df_raw)
            pd.DataFrame([[f"ã€ç‚¹å¾ªç¯ â€” {year} ä¼ä¸šæŒ‡æ ‡(C7-C10)ã€‘"]]).to_excel(
                writer, sheet_name=ws_name, startrow=row,
                index=False, header=False,
            )
            row += 1
            ind_y.to_excel(
                writer, sheet_name=ws_name, startrow=row, index=False,
            )
            row += len(ind_y) + 2
        if has_layers:
            pd.DataFrame({
                "å¹´åº¦": mc["å¹´åº¦"].values,
                "ç‚¹å¾ªç¯è¯„åˆ†(ä¼ä¸šå‡å€¼)": ls["ç‚¹å¾ªç¯"],
                "å±‚é¢æƒé‡": round(lw["ç‚¹å¾ªç¯"], 4),
            }).to_excel(
                writer, sheet_name=ws_name, startrow=row, index=False,
            )

        # â”€â”€ Sheet 3: æƒé‡æ˜ç»† â”€â”€
        row = 0
        ws_name = "æƒé‡æ˜ç»†"
        if "weight_df" in st.session_state:
            pd.DataFrame([["ã€C1-C10 ç»„åˆæƒé‡ã€‘"]]).to_excel(
                writer, sheet_name=ws_name, startrow=row,
                index=False, header=False,
            )
            row += 1
            wdf = st.session_state["weight_df"]
            wdf.to_excel(
                writer, sheet_name=ws_name, startrow=row, index=False,
            )
            row += len(wdf) + 2

        pd.DataFrame([["ã€ç‚¹å¾ªç¯å½’ä¸€åŒ–æƒé‡(C7-C10)ã€‘"]]).to_excel(
            writer, sheet_name=ws_name, startrow=row,
            index=False, header=False,
        )
        row += 1
        micro_weight_df.to_excel(
            writer, sheet_name=ws_name, startrow=row, index=False,
        )
        row += len(micro_weight_df) + 2

        if has_layers:
            pd.DataFrame([["ã€å±‚é¢æƒé‡ã€‘"]]).to_excel(
                writer, sheet_name=ws_name, startrow=row,
                index=False, header=False,
            )
            row += 1
            pd.DataFrame({
                "å±‚é¢": list(lw.keys()),
                "æƒé‡": [round(v, 4) for v in lw.values()],
            }).to_excel(
                writer, sheet_name=ws_name, startrow=row, index=False,
            )

    st.download_button(
        "ä¸‹è½½è¯„ä»·ç»“æœ (Excel)",
        data=buf.getvalue(),
        file_name="æ°´æ•ˆè¯„ä»·ç»“æœ.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )

    st.session_state["result_df"] = result_df

# ================================================================
# Tab 4: å¯è§†åŒ–åˆ†æ
# ================================================================
with tab4:
    st.header("å¯è§†åŒ–åˆ†æ")

    if "result_df" not in st.session_state:
        st.warning("è¯·å…ˆå®Œæˆ TOPSIS è¯„ä»·")
        st.stop()

    result_df = st.session_state["result_df"]
    ind_micro = st.session_state["ind_micro"]
    micro_cols = [c for c in ind_micro.columns if c.startswith("C")]

    # â”€â”€ è¯•ç‚¹è¯„åˆ†è¶‹åŠ¿ï¼ˆåˆ†å±‚ + æ±‡æ€»ï¼‰â”€â”€
    if "pilot_df" in st.session_state:
        st.subheader("è¯•ç‚¹è¯„åˆ†è¶‹åŠ¿")
        pilot_df = st.session_state["pilot_df"]
        fig_pilot = go.Figure()
        for col_name in ["å¤§å¾ªç¯è¯„åˆ†", "å°å¾ªç¯è¯„åˆ†", "ç‚¹å¾ªç¯è¯„åˆ†"]:
            fig_pilot.add_trace(go.Scatter(
                x=pilot_df["å¹´åº¦"], y=pilot_df[col_name],
                mode="lines+markers", name=col_name,
                line=dict(dash="dot"),
            ))
        fig_pilot.add_trace(go.Scatter(
            x=pilot_df["å¹´åº¦"], y=pilot_df["æ±‡æ€»è¯„åˆ†"],
            mode="lines+markers+text",
            text=pilot_df["æ±‡æ€»è¯„åˆ†"].astype(str),
            textposition="top center", name="æ±‡æ€»è¯„åˆ†",
            line=dict(width=3),
        ))
        fig_pilot.update_layout(height=400, title="è¯•ç‚¹æ°´æ•ˆè¯„åˆ†è¶‹åŠ¿",
                                yaxis_range=[0, 100])
        st.plotly_chart(fig_pilot, use_container_width=True)

    # â”€â”€ å„å±‚é¢æŒ‡æ ‡è¶‹åŠ¿ â”€â”€
    if "merged_clean" in st.session_state:
        merged_clean = st.session_state["merged_clean"]
        all_cols = st.session_state["indicator_cols"]

        st.subheader("å„å±‚é¢æŒ‡æ ‡è¶‹åŠ¿")
        col_t1, col_t2, col_t3 = st.columns(3)

        with col_t1:
            macro_cols_t = [c for c in all_cols if c.split("-")[0] in ("C1", "C2", "C3", "C4")]
            fig_m = go.Figure()
            for c in macro_cols_t:
                fig_m.add_trace(go.Scatter(
                    x=merged_clean["å¹´åº¦"], y=merged_clean[c],
                    mode="lines+markers",
                    name=c.split("-")[1] if "-" in c else c,
                ))
            fig_m.update_layout(height=350, title="å¤§å¾ªç¯ (C1-C4)")
            st.plotly_chart(fig_m, use_container_width=True)

        with col_t2:
            meso_cols_t = [c for c in all_cols if c.split("-")[0] in ("C5", "C6")]
            fig_s = go.Figure()
            for c in meso_cols_t:
                fig_s.add_trace(go.Scatter(
                    x=merged_clean["å¹´åº¦"], y=merged_clean[c],
                    mode="lines+markers",
                    name=c.split("-")[1] if "-" in c else c,
                ))
            fig_s.update_layout(height=350, title="å°å¾ªç¯ (C5-C6)")
            st.plotly_chart(fig_s, use_container_width=True)

        with col_t3:
            micro_cols_t = [c for c in all_cols if c.split("-")[0] in ("C7", "C8", "C9", "C10")]
            fig_p = go.Figure()
            for c in micro_cols_t:
                fig_p.add_trace(go.Scatter(
                    x=merged_clean["å¹´åº¦"], y=merged_clean[c],
                    mode="lines+markers",
                    name=c.split("-")[1] if "-" in c else c,
                ))
            fig_p.update_layout(height=350, title="ç‚¹å¾ªç¯å‡å€¼ (C7-C10)")
            st.plotly_chart(fig_p, use_container_width=True)

    # â”€â”€ ä¼ä¸šé›·è¾¾å›¾ â”€â”€
    st.subheader("ä¼ä¸šæ°´æ•ˆé›·è¾¾å›¾")
    selected = st.multiselect(
        "é€‰æ‹©ä¼ä¸š", ind_micro["ä¼ä¸šåç§°"].tolist(),
        default=ind_micro["ä¼ä¸šåç§°"].tolist()[:3],
    )
    if selected:
        fig_radar = go.Figure()
        for name in selected:
            row = ind_micro[ind_micro["ä¼ä¸šåç§°"] == name][micro_cols].values[0]
            fig_radar.add_trace(go.Scatterpolar(
                r=list(row) + [row[0]],
                theta=[c.split("-")[0] for c in micro_cols] + [micro_cols[0].split("-")[0]],
                name=name,
                fill="toself",
                opacity=0.6,
            ))
        fig_radar.update_layout(
            polar=dict(radialaxis=dict(visible=True)),
            height=450,
        )
        st.plotly_chart(fig_radar, use_container_width=True)

    # â”€â”€ å¾—åˆ†æŸ±çŠ¶å›¾ â”€â”€
    st.subheader("æ°´æ•ˆè¯„åˆ†æ’å")
    fig_bar = px.bar(
        result_df.sort_values("æ°´æ•ˆè¯„åˆ†"),
        x="æ°´æ•ˆè¯„åˆ†", y="ä¼ä¸šåç§°",
        orientation="h",
        color="æ°´æ•ˆç­‰çº§",
        color_discrete_map={
            "æ°´æ•ˆé¢†è·‘": "#1890ff",
            "æ°´æ•ˆå…ˆè¿›": "#52c41a",
            "æ°´æ•ˆè¾¾æ ‡": "#faad14",
            "æ°´æ•ˆå¾…æ”¹è¿›": "#f5222d",
        },
    )
    for threshold in [40, 60, 80]:
        fig_bar.add_vline(x=threshold, line_dash="dash", line_color="gray")
    fig_bar.update_layout(height=350)
    st.plotly_chart(fig_bar, use_container_width=True)
